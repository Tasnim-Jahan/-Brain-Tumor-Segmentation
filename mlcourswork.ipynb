{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7054314,"sourceType":"datasetVersion","datasetId":4041872}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import CustomObjectScope\nfrom sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\n\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation\nfrom tensorflow.keras.layers import MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-05T09:25:14.658614Z","iopub.execute_input":"2023-12-05T09:25:14.659336Z","iopub.status.idle":"2023-12-05T09:25:26.207638Z","shell.execute_reply.started":"2023-12-05T09:25:14.659302Z","shell.execute_reply":"2023-12-05T09:25:26.206862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:26.209403Z","iopub.execute_input":"2023-12-05T09:25:26.209926Z","iopub.status.idle":"2023-12-05T09:25:26.214468Z","shell.execute_reply.started":"2023-12-05T09:25:26.209900Z","shell.execute_reply":"2023-12-05T09:25:26.213457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conv Block","metadata":{}},{"cell_type":"code","source":"def conv_block(inputs, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:26.215777Z","iopub.execute_input":"2023-12-05T09:25:26.216113Z","iopub.status.idle":"2023-12-05T09:25:26.236182Z","shell.execute_reply.started":"2023-12-05T09:25:26.216079Z","shell.execute_reply":"2023-12-05T09:25:26.235350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoder Block","metadata":{}},{"cell_type":"code","source":"def encoder_block(inputs, num_filters):\n    x = conv_block(inputs, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:26.237112Z","iopub.execute_input":"2023-12-05T09:25:26.237401Z","iopub.status.idle":"2023-12-05T09:25:26.245585Z","shell.execute_reply.started":"2023-12-05T09:25:26.237377Z","shell.execute_reply":"2023-12-05T09:25:26.244770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decoder Block","metadata":{}},{"cell_type":"code","source":"def decoder_block(inputs, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:26.248533Z","iopub.execute_input":"2023-12-05T09:25:26.249277Z","iopub.status.idle":"2023-12-05T09:25:26.254780Z","shell.execute_reply.started":"2023-12-05T09:25:26.249241Z","shell.execute_reply":"2023-12-05T09:25:26.253920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Build U-Net","metadata":{}},{"cell_type":"code","source":"def unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"UNET\")\n    return model\n\nmodel = unet((256,256,3))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:26.255753Z","iopub.execute_input":"2023-12-05T09:25:26.256014Z","iopub.status.idle":"2023-12-05T09:25:29.849510Z","shell.execute_reply.started":"2023-12-05T09:25:26.255991Z","shell.execute_reply":"2023-12-05T09:25:29.848673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dice Loss","metadata":{}},{"cell_type":"code","source":"smooth = 1e-15\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:29.850710Z","iopub.execute_input":"2023-12-05T09:25:29.850999Z","iopub.status.idle":"2023-12-05T09:25:29.857018Z","shell.execute_reply.started":"2023-12-05T09:25:29.850972Z","shell.execute_reply":"2023-12-05T09:25:29.856052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the model","metadata":{}},{"cell_type":"code","source":"H = 256\nW = 256\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\ncreate_dir(\"files\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:29.858271Z","iopub.execute_input":"2023-12-05T09:25:29.858531Z","iopub.status.idle":"2023-12-05T09:25:29.868525Z","shell.execute_reply.started":"2023-12-05T09:25:29.858508Z","shell.execute_reply":"2023-12-05T09:25:29.867567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(path, split=0.1):\n    images = sorted(glob(os.path.join(path, \"trainval-image\", \"*.jpg\")))\n    masks = sorted(glob(os.path.join(path, \"trainval-mask\", \"*.jpg\")))\n\n    split_size = int(len(images) * split)\n\n    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n \n    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:29.869622Z","iopub.execute_input":"2023-12-05T09:25:29.869881Z","iopub.status.idle":"2023-12-05T09:25:29.879237Z","shell.execute_reply.started":"2023-12-05T09:25:29.869857Z","shell.execute_reply":"2023-12-05T09:25:29.878275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_image(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\ndef read_mask(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n    x = cv2.resize(x, (W, H))   ## (h, w)\n    x = x / 255.0               ## (h, w)\n    x = x.astype(np.float32)    ## (h, w)\n    x = np.expand_dims(x, axis=-1)## (h, w, 1)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:29.880420Z","iopub.execute_input":"2023-12-05T09:25:29.880684Z","iopub.status.idle":"2023-12-05T09:25:29.889741Z","shell.execute_reply.started":"2023-12-05T09:25:29.880655Z","shell.execute_reply":"2023-12-05T09:25:29.888866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape([H, W, 3])\n    y.set_shape([H, W, 1])\n    return x, y\n\ndef tf_dataset(X, Y, batch=2):\n    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(10)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:29.891033Z","iopub.execute_input":"2023-12-05T09:25:29.891644Z","iopub.status.idle":"2023-12-05T09:25:29.903600Z","shell.execute_reply.started":"2023-12-05T09:25:29.891610Z","shell.execute_reply":"2023-12-05T09:25:29.902689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nlr = 1e-4\nnum_epochs = 300\nmodel_path = os.path.join(\"files\", \"model.h5\")\ncsv_path = os.path.join(\"files\", \"log.csv\")\ndataset_path=\"/kaggle/input/tn3k-thyroid-nodule-region-segmentation-dataset\"","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:29.904922Z","iopub.execute_input":"2023-12-05T09:25:29.905336Z","iopub.status.idle":"2023-12-05T09:25:29.914836Z","shell.execute_reply.started":"2023-12-05T09:25:29.905302Z","shell.execute_reply":"2023-12-05T09:25:29.913953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_list = [os.path.join(dataset_path,i) for i in os.listdir(dataset_path)]\nsize_dict = {}\nfor i,value in enumerate(dir_list):\n    size_dict[os.listdir(dataset_path)[i]] = len(os.listdir(value))\nsize_dict ","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:29.916009Z","iopub.execute_input":"2023-12-05T09:25:29.916371Z","iopub.status.idle":"2023-12-05T09:25:31.029377Z","shell.execute_reply.started":"2023-12-05T09:25:29.916338Z","shell.execute_reply":"2023-12-05T09:25:31.028202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path) #(train_x, train_y), (valid_x, valid_y) = load_dataset(dataset_path)#\n\nprint(f\"Train: ({len(train_x)},{len(train_y)})\")\nprint(f\"Valid: ({len(valid_x)},{len(valid_y)})\")\nprint(f\"Test: ({len(test_x)},{len(test_y)})\")#will scheck x or y","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:31.035898Z","iopub.execute_input":"2023-12-05T09:25:31.037034Z","iopub.status.idle":"2023-12-05T09:25:31.082996Z","shell.execute_reply.started":"2023-12-05T09:25:31.036956Z","shell.execute_reply":"2023-12-05T09:25:31.081246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\nvalid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\ntest_dataset = tf_dataset(test_x, test_y, batch=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:31.085502Z","iopub.execute_input":"2023-12-05T09:25:31.086330Z","iopub.status.idle":"2023-12-05T09:25:31.345183Z","shell.execute_reply.started":"2023-12-05T09:25:31.086254Z","shell.execute_reply":"2023-12-05T09:25:31.343634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet((H, W, 3))\nmodel.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef,'accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:31.347312Z","iopub.execute_input":"2023-12-05T09:25:31.347861Z","iopub.status.idle":"2023-12-05T09:25:31.978681Z","shell.execute_reply.started":"2023-12-05T09:25:31.347814Z","shell.execute_reply":"2023-12-05T09:25:31.977913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n        CSVLogger(csv_path),\n        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n    ]","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:31.979758Z","iopub.execute_input":"2023-12-05T09:25:31.980052Z","iopub.status.idle":"2023-12-05T09:25:31.985111Z","shell.execute_reply.started":"2023-12-05T09:25:31.980026Z","shell.execute_reply":"2023-12-05T09:25:31.984286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n        train_dataset,\n        epochs=num_epochs,\n        validation_data=valid_dataset,\n        callbacks=callbacks,\n        verbose=1,\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-05T09:25:31.986232Z","iopub.execute_input":"2023-12-05T09:25:31.986507Z","iopub.status.idle":"2023-12-05T10:03:12.173571Z","shell.execute_reply.started":"2023-12-05T09:25:31.986483Z","shell.execute_reply":"2023-12-05T10:03:12.172502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learnig curves","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nmetrics = pd.read_csv(\"/kaggle/working/files/log.csv\")\nmetrics.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:03:12.174910Z","iopub.execute_input":"2023-12-05T10:03:12.175318Z","iopub.status.idle":"2023-12-05T10:03:12.203975Z","shell.execute_reply.started":"2023-12-05T10:03:12.175279Z","shell.execute_reply":"2023-12-05T10:03:12.203030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics.tail(2)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:03:12.205353Z","iopub.execute_input":"2023-12-05T10:03:12.205633Z","iopub.status.idle":"2023-12-05T10:03:12.216881Z","shell.execute_reply.started":"2023-12-05T10:03:12.205607Z","shell.execute_reply":"2023-12-05T10:03:12.216025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dice_coef","metadata":{}},{"cell_type":"code","source":"metrics[['dice_coef','val_dice_coef']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:03:12.218114Z","iopub.execute_input":"2023-12-05T10:03:12.218427Z","iopub.status.idle":"2023-12-05T10:03:12.563098Z","shell.execute_reply.started":"2023-12-05T10:03:12.218402Z","shell.execute_reply":"2023-12-05T10:03:12.562177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['accuracy','val_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:03:12.564360Z","iopub.execute_input":"2023-12-05T10:03:12.564651Z","iopub.status.idle":"2023-12-05T10:03:12.866866Z","shell.execute_reply.started":"2023-12-05T10:03:12.564625Z","shell.execute_reply":"2023-12-05T10:03:12.865946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['loss','val_loss']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:03:12.868207Z","iopub.execute_input":"2023-12-05T10:03:12.868587Z","iopub.status.idle":"2023-12-05T10:03:13.168974Z","shell.execute_reply.started":"2023-12-05T10:03:12.868553Z","shell.execute_reply":"2023-12-05T10:03:13.168058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"results\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:11:52.858322Z","iopub.execute_input":"2023-12-05T10:11:52.859181Z","iopub.status.idle":"2023-12-05T10:11:52.863083Z","shell.execute_reply.started":"2023-12-05T10:11:52.859144Z","shell.execute_reply":"2023-12-05T10:11:52.862092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef save_results(image, mask, y_pred, save_image_path):\n    mask = np.expand_dims(mask, axis=-1)\n    mask = np.concatenate([mask, mask, mask], axis=-1)\n\n    y_pred = np.expand_dims(y_pred, axis=-1)\n    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n    y_pred = y_pred * 255\n\n    line = np.ones((H, 10, 3)) * 255\n\n    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n    cv2.imwrite(save_image_path, cat_images)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:11:55.637433Z","iopub.execute_input":"2023-12-05T10:11:55.638304Z","iopub.status.idle":"2023-12-05T10:11:55.644735Z","shell.execute_reply.started":"2023-12-05T10:11:55.638265Z","shell.execute_reply":"2023-12-05T10:11:55.643701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Prediction and Evaluation\"\"\"\nSCORE = []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results\", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE.append([name, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore = [s[1:]for s in SCORE]\nscore = np.mean(score, axis=0)\nprint(f\"F1: {score[0]:0.5f}\")\nprint(f\"Jaccard: {score[1]:0.5f}\")\nprint(f\"Recall: {score[2]:0.5f}\")\nprint(f\"Precision: {score[3]:0.5f}\")\n\ndf = pd.DataFrame(SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:11:59.632756Z","iopub.execute_input":"2023-12-05T10:11:59.633625Z","iopub.status.idle":"2023-12-05T10:12:53.773790Z","shell.execute_reply.started":"2023-12-05T10:11:59.633590Z","shell.execute_reply":"2023-12-05T10:12:53.772869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score.csv\")\nscores.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:12:58.179745Z","iopub.execute_input":"2023-12-05T10:12:58.180475Z","iopub.status.idle":"2023-12-05T10:12:58.193811Z","shell.execute_reply.started":"2023-12-05T10:12:58.180441Z","shell.execute_reply":"2023-12-05T10:12:58.193035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot predicted images","metadata":{}},{"cell_type":"code","source":"dir = \"/kaggle/working/results/\"\nimages = os.listdir(\"/kaggle/working/results\")[:5]\nimg1 = plt.imread(dir+images[0])\nplt.imshow(img1, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:13:00.797902Z","iopub.execute_input":"2023-12-05T10:13:00.798655Z","iopub.status.idle":"2023-12-05T10:13:01.087030Z","shell.execute_reply.started":"2023-12-05T10:13:00.798619Z","shell.execute_reply":"2023-12-05T10:13:01.086191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = plt.imread(dir+images[1])\nplt.imshow(img1, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:13:02.446735Z","iopub.execute_input":"2023-12-05T10:13:02.447475Z","iopub.status.idle":"2023-12-05T10:13:02.657584Z","shell.execute_reply.started":"2023-12-05T10:13:02.447439Z","shell.execute_reply":"2023-12-05T10:13:02.656647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = plt.imread(dir+images[2])\nplt.imshow(img1, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:13:03.732093Z","iopub.execute_input":"2023-12-05T10:13:03.732934Z","iopub.status.idle":"2023-12-05T10:13:03.945718Z","shell.execute_reply.started":"2023-12-05T10:13:03.732899Z","shell.execute_reply":"2023-12-05T10:13:03.944852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16,VGG19","metadata":{"execution":{"iopub.status.busy":"2023-12-05T12:05:24.378445Z","iopub.execute_input":"2023-12-05T12:05:24.378955Z","iopub.status.idle":"2023-12-05T12:05:24.383909Z","shell.execute_reply.started":"2023-12-05T12:05:24.378915Z","shell.execute_reply":"2023-12-05T12:05:24.382848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-12-05T12:05:25.738969Z","iopub.execute_input":"2023-12-05T12:05:25.739889Z","iopub.status.idle":"2023-12-05T12:05:25.746545Z","shell.execute_reply.started":"2023-12-05T12:05:25.739853Z","shell.execute_reply":"2023-12-05T12:05:25.745513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_vgg16_unet(input_shape):\n    \"\"\" Input \"\"\"\n    inputs = Input(input_shape)\n\n    \"\"\" Pre-trained VGG16 Model \"\"\"\n    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n\n    \"\"\" Encoder \"\"\"\n    s1 = vgg16.get_layer(\"block1_conv2\").output         ## (512 x 512)\n    s2 = vgg16.get_layer(\"block2_conv2\").output         ## (256 x 256)\n    s3 = vgg16.get_layer(\"block3_conv3\").output         ## (128 x 128)\n    s4 = vgg16.get_layer(\"block4_conv3\").output         ## (64 x 64)\n\n    \"\"\" Bridge \"\"\"\n    b1 = vgg16.get_layer(\"block5_conv3\").output         ## (32 x 32)\n\n    \"\"\" Decoder \"\"\"\n    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n\n    \"\"\" Output \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"VGG16_U-Net\")\n    return model\n\n\n    input_shape = ((512, 512, 3))\n    model = build_vgg16_unet(input_shape)\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T12:41:49.917443Z","iopub.execute_input":"2023-12-05T12:41:49.918116Z","iopub.status.idle":"2023-12-05T12:41:49.926402Z","shell.execute_reply.started":"2023-12-05T12:41:49.918082Z","shell.execute_reply":"2023-12-05T12:41:49.925399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n\ndef build_vgg16_unet(input_shape):\n    \"\"\" Input \"\"\"\n    inputs = Input(input_shape)\n\n    \"\"\" Pre-trained VGG16 Model \"\"\"\n    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n\n    \"\"\" Encoder \"\"\"\n    s1 = vgg16.get_layer(\"block1_conv2\").output         ## (512 x 512)\n    s2 = vgg16.get_layer(\"block2_conv2\").output         ## (256 x 256)\n    s3 = vgg16.get_layer(\"block3_conv3\").output         ## (128 x 128)\n    s4 = vgg16.get_layer(\"block4_conv3\").output         ## (64 x 64)\n\n    \"\"\" Bridge \"\"\"\n    b1 = vgg16.get_layer(\"block5_conv3\").output         ## (32 x 32)\n\n    \"\"\" Decoder \"\"\"\n    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n\n    \"\"\" Output \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"VGG16_U-Net\")\n    return model\n\n#if __name__ == \"__main__\":\n    #input_shape = (512, 512, 3)\n    #model = build_vgg16_unet(input_shape)\n    #model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T12:44:41.553096Z","iopub.execute_input":"2023-12-05T12:44:41.553998Z","iopub.status.idle":"2023-12-05T12:44:41.564505Z","shell.execute_reply.started":"2023-12-05T12:44:41.553963Z","shell.execute_reply":"2023-12-05T12:44:41.563425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_vgg16_unet((256,256,3))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T12:44:45.576450Z","iopub.execute_input":"2023-12-05T12:44:45.577109Z","iopub.status.idle":"2023-12-05T12:44:46.329825Z","shell.execute_reply.started":"2023-12-05T12:44:45.577077Z","shell.execute_reply":"2023-12-05T12:44:46.328826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_vgg19_unet(input_shape):\n    \"\"\" Input \"\"\"\n    inputs = Input(input_shape)\n\n    \"\"\" Pre-trained VGG19 Model \"\"\"\n    vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n\n    \"\"\" Encoder \"\"\"\n    s1 = vgg19.get_layer(\"block1_conv2\").output         ## (512 x 512)\n    s2 = vgg19.get_layer(\"block2_conv2\").output         ## (256 x 256)\n    s3 = vgg19.get_layer(\"block3_conv4\").output         ## (128 x 128)\n    s4 = vgg19.get_layer(\"block4_conv4\").output         ## (64 x 64)\n\n    \"\"\" Bridge \"\"\"\n    b1 = vgg19.get_layer(\"block5_conv4\").output         ## (32 x 32)\n\n    \"\"\" Decoder \"\"\"\n    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n\n    \"\"\" Output \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"VGG19_U-Net\")\n    return model\n\n#if __name__ == \"__main__\":\n    #input_shape = (512, 512, 3)#\n    #model = build_vgg19_unet(input_shape)\n    #model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T12:46:40.582271Z","iopub.execute_input":"2023-12-05T12:46:40.583163Z","iopub.status.idle":"2023-12-05T12:46:40.590947Z","shell.execute_reply.started":"2023-12-05T12:46:40.583114Z","shell.execute_reply":"2023-12-05T12:46:40.589953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_vgg19_unet((256,256,3))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T12:47:14.825582Z","iopub.execute_input":"2023-12-05T12:47:14.825961Z","iopub.status.idle":"2023-12-05T12:47:15.588703Z","shell.execute_reply.started":"2023-12-05T12:47:14.825927Z","shell.execute_reply":"2023-12-05T12:47:15.587830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet((H, W, 3))\nmodel.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef,'accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#input_shape = (512, 512, 3)\ninput_shape = (256, 256, 3)\n\n# Functions returning uncompiled Keras models\nmodels = {\n    'build_vgg16_unet': build_vgg16_unet(input_shape),\n    'build_vgg19_unet': build_vgg19_unet(input_shape),\n}\n\n# Compiling each model\nfor name, model in models.items():\n    model.compile(\n        optimizer='adam',  # or any other optimizer\n        loss='binary_crossentropy',  # or any other loss function suitable for your problem\n        metrics=['accuracy']  # or other metrics you want to track\n    )\n\n# Training each model\nfor name, model in models.items():\n    model.fit(\n        train_dataset,\n        epochs=num_epochs,\n        validation_data=valid_dataset,\n        callbacks=callbacks,\n        verbose=1,\n    )\n\n# Evaluating each model\nfor name, model in models.items():\n    loss, accuracy = model.evaluate(X_test, y_test)\n    print(f\"Accuracy Score for {name} is: {accuracy * 100}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:28:36.148972Z","iopub.execute_input":"2023-12-05T14:28:36.149787Z","iopub.status.idle":"2023-12-05T14:28:55.369911Z","shell.execute_reply.started":"2023-12-05T14:28:36.149748Z","shell.execute_reply":"2023-12-05T14:28:55.368442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = unet((H, W, 3))\n#model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef,'accuracy'])\n\n#input_shape = (512, 512, 3)\ninput_shape = (256, 256, 3)\n\n# Functions returning uncompiled Keras models\nmodels = {\n    'build_vgg16_unet': build_vgg16_unet(input_shape),\n    'build_vgg19_unet': build_vgg19_unet(input_shape),\n}\n\n# Compiling each model\nfor name, model in models.items():\n    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef,'accuracy'])\n    #model.compile(\n        #optimizer='adam',  # or any other optimizer\n        #loss='binary_crossentropy',  # or any other loss function suitable for your problem\n        #metrics=['accuracy']  # or other metrics you want to track\n    #)\n\n# Training each model\nfor name, model in models.items():\n    model.fit(\n        train_dataset,\n        epochs=num_epochs,\n        validation_data=valid_dataset,\n        callbacks=callbacks,\n        verbose=1,\n    )\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:24:44.836369Z","iopub.execute_input":"2023-12-05T15:24:44.836773Z","iopub.status.idle":"2023-12-05T15:24:45.079882Z","shell.execute_reply.started":"2023-12-05T15:24:44.836741Z","shell.execute_reply":"2023-12-05T15:24:45.078502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating each model\nfor name, model in models.items():\n    loss, accuracy = model.evaluate(valid_x, valid_y)\n    print(f\"Accuracy Score for {name} is: {accuracy * 100}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:12:53.654180Z","iopub.execute_input":"2023-12-05T15:12:53.655098Z","iopub.status.idle":"2023-12-05T15:12:53.790900Z","shell.execute_reply.started":"2023-12-05T15:12:53.655060Z","shell.execute_reply":"2023-12-05T15:12:53.789698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmetrics = pd.read_csv(\"/kaggle/working/files/log.csv\")\nmetrics.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:14:46.802530Z","iopub.execute_input":"2023-12-05T15:14:46.803513Z","iopub.status.idle":"2023-12-05T15:14:46.818023Z","shell.execute_reply.started":"2023-12-05T15:14:46.803474Z","shell.execute_reply":"2023-12-05T15:14:46.817187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"metrics[['dice_coef','val_dice_coef']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:16:37.729845Z","iopub.execute_input":"2023-12-05T15:16:37.730450Z","iopub.status.idle":"2023-12-05T15:16:38.025793Z","shell.execute_reply.started":"2023-12-05T15:16:37.730407Z","shell.execute_reply":"2023-12-05T15:16:38.024945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['accuracy','val_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:16:56.218458Z","iopub.execute_input":"2023-12-05T15:16:56.219328Z","iopub.status.idle":"2023-12-05T15:16:56.523778Z","shell.execute_reply.started":"2023-12-05T15:16:56.219291Z","shell.execute_reply":"2023-12-05T15:16:56.522639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['loss','val_loss']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:17:13.966186Z","iopub.execute_input":"2023-12-05T15:17:13.966567Z","iopub.status.idle":"2023-12-05T15:17:14.269995Z","shell.execute_reply.started":"2023-12-05T15:17:13.966533Z","shell.execute_reply":"2023-12-05T15:17:14.268940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Prediction and Evaluation\"\"\"\nSCORE = []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results\", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE.append([name, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore = [s[1:]for s in SCORE]\nscore = np.mean(score, axis=0)\nprint(f\"F1: {score[0]:0.5f}\")\nprint(f\"Jaccard: {score[1]:0.5f}\")\nprint(f\"Recall: {score[2]:0.5f}\")\nprint(f\"Precision: {score[3]:0.5f}\")\n\ndf = pd.DataFrame(SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:19:22.008604Z","iopub.execute_input":"2023-12-05T15:19:22.009344Z","iopub.status.idle":"2023-12-05T15:20:17.175910Z","shell.execute_reply.started":"2023-12-05T15:19:22.009307Z","shell.execute_reply":"2023-12-05T15:20:17.173052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score.csv\")\nscores.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:20:51.817558Z","iopub.execute_input":"2023-12-05T15:20:51.818213Z","iopub.status.idle":"2023-12-05T15:20:51.831414Z","shell.execute_reply.started":"2023-12-05T15:20:51.818178Z","shell.execute_reply":"2023-12-05T15:20:51.830497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir = \"/kaggle/working/results/\"\nimages = os.listdir(\"/kaggle/working/results\")[:5]\nimg1 = plt.imread(dir+images[0])\nplt.imshow(img1, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:20:56.853348Z","iopub.execute_input":"2023-12-05T15:20:56.854014Z","iopub.status.idle":"2023-12-05T15:20:57.140944Z","shell.execute_reply.started":"2023-12-05T15:20:56.853977Z","shell.execute_reply":"2023-12-05T15:20:57.140028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}